\section{Part II: Contributions to Language Model Alignment}

% \begin{frame}[plain]
%     \centering
%     \vfill
%     \Huge Part II\\[0.75em]\textbf{Contributions to Language Model Alignment}
%     \vfill
% \end{frame}

\begin{frame}[plain, noframenumbering]{Overview}
    \setlength{\parskip}{1em}
    \tableofcontents[currentsection]
\end{frame}

\begin{frame}{Motivation}
    \addtocounter{framenumber}{-1}
    \begin{columns}
        \begin{column}{0.5\linewidth}
            \begin{itemize}
                \item Chatbots based on Transformers~\footnotemark[5]
                \item Hallucinations \(\approx\) false information, out of topic, rambling, toxic...
                \item How to mitigate them?
            \end{itemize}
        \end{column}
        \begin{column}{0.5\linewidth}
            \begin{figure}
                \centering
                \includegraphics[width=\textwidth]{figures/part2/aircanada.png}
                % \caption{Air Canada's chatbot invented a refund policy while interatcing with client. [\href{URLhttps://arstechnica.com/tech-policy/2024/02/air-canada-must-honor-refund-policy-invented-by-airlines-chatbot/}{Source}]}
                \label{fig:part2:aircanada}
            \end{figure}
        \end{column}
    \end{columns}
    \grayfootnotetext[5]{\citet{Vaswani2017attention}}
\end{frame}

\begin{frame}{Background on Language Models}
    \begin{itemize}
        \item \textit{Vocabulary} \(\mathcal{V}\) = set of \textit{tokens} (``pieces of words'')
        \item Language model
        \begin{equation*}
           \pi_\theta : x = (\textup{token}_1, \dotsc, \textup{token}_L) \mapsto \pi_\theta (\, \cdot \, \vert x) = \text{proba. over } \mathcal{V}
        \end{equation*}
        \vspace*{-2\baselineskip}\pause
        \item Autoregressive generation: \textit{prompt} \(x\) \(\to\) \textit{response} \(y\)
        \begin{align*}
            y_1 &\sim \pi_\theta (\, \cdot \, \vert x) \\
            y_2 &\sim \pi_\theta (\, \cdot \, \vert x, y_1) \\
            &\vdots \\ 
            y_t &\sim \pi_\theta (\, \cdot \, \vert x, y_{<t})
        \end{align*}
        % \item[{\color{white}\ding{118}}] {\color{white}Autoregressive generation: \textit{prompt} \(x\) \(\to\) \textit{generate} \(y\)
        % \begin{align*}
        %     y_1 &\sim \pi_\theta (\, \cdot \, \vert x) \\
        %     y_2 &\sim \pi_\theta (\, \cdot \, \vert x, y_1) \\
        %     &\vdots \\ 
        %     y_t &\sim \pi_\theta (\, \cdot \, \vert x, y_{<t})
        % \end{align*}}
    \end{itemize}
\end{frame}

% \begin{frame}{Background on Language Models}
%     \addtocounter{framenumber}{-1}
%     \begin{itemize}
%         \item \textit{Vocabulary} \(\mathcal{V}\) = set of \textit{tokens} (``pieces of words'')
%         \item Language model
%         \begin{equation*}
%            \pi_\theta : x = (\textup{token}_1, \dotsc, \textup{token}_L) \mapsto \pi_\theta (\, \cdot \, \vert x) = \text{proba. over } \mathcal{V}
%         \end{equation*}
%         \item Autoregressive generation: \textit{prompt} \(x\) \(\to\) \textit{response} \(y\)
%         \begin{align*}
%             y_1 &\sim \pi_\theta (\, \cdot \, \vert x) \\
%             y_2 &\sim \pi_\theta (\, \cdot \, \vert x, y_1) \\
%             &\vdots \\ 
%             y_t &\sim \pi_\theta (\, \cdot \, \vert x, y_{<t})
%         \end{align*}
%     \end{itemize}
% \end{frame}

% \begin{frame}{Background on Language Models}

% \begin{minipage}[t][10em][t]{\textwidth}
%     \only<1>{
%         \textit{Pre-training}: given a dataset 
%         \(\mathcal{D}_{\textup{pre}}\), find \(\theta\) minimizing
%         \begin{equation*}
%             \ell(\theta;\mathcal{D}_{\textup{pre}})
%             \coloneqq
%             - \sum_{x \in \mathcal{D}_{\textup{pre}}}
%               \sum_{i=1}^{\lvert x \rvert}
%               \log \pi_\theta(x_{i+1} \mid x_{\le i})
%         \end{equation*}
%     }
%     \only<2>{
%         \textit{SFT}: given a task-specific dataset 
%         \(\mathcal{D}_{\textup{SFT}}\), find \(\theta\) minimizing
%         \begin{equation*}
%             \ell(\theta;\mathcal{D}_{\textup{SFT}})
%             \coloneqq
%             - \sum_{x \in \mathcal{D}_{\textup{SFT}}}
%               \sum_{i=1}^{\lvert x \rvert}
%               \log \pi_\theta(x_{i+1} \mid x_{\le i})
%         \end{equation*}
%     }
%     \only<3>{
%         \frametitle{Retrieval Augmented Generation: NPOV Task~\citep{chang2024detectinghallucinationcoverageerrors}}
%     }
%     \only<4-5>{
%         \textcolor{myorange}{\textit{Alignment}} to human preferences via RL~\citep{christiano2023deepreinforcementlearninghuman}:\\[-0.25em]
%         \begin{enumerate}
%             \item<4-5> Train a \textit{reward} model \(\textcolor{myorange}{R}\)
%                   on human preference data \(\mathcal{D}_{\textup{RM}}\)
%             \item<5> Update the \textit{writer} model \(\pi_{\textup{SFT}}\)
%         \end{enumerate}

%         \only<5>{
%         \begin{equation*}
%             \pi_{\color{lightblue}\beta}
%             \in \arg\max_{\pi}\,
%             \mathbb{E}_{\substack{x \sim \mathcal{D}_{\textup{RL}} \\ y \sim p(y\mid x)}}\!\left[\textcolor{myorange}{R(x, y)}\right]
%             - \textcolor{lightblue}{\beta}\;
%               \textup{KL}\!\left(\pi \Vert \pi_{\textup{SFT}}\right)
%         \end{equation*}
%         }
%     }
%     \only<6>{
%         \textit{Parameter-efficient tuning} \(\Rightarrow\) LoRA~\citep{hu2021loralowrankadaptationlarge}:\\[1em]
%         \begin{equation*}
%             \theta = \theta_{\textup{SFT}} + \underbrace{A B}_{\text{low rank } r}
%         \end{equation*}
%     }
%     \only<7>{
%         Evaluation via \textit{autorater}: large model capable of classification\\[1em]
%         \begin{figure}
%             \centering
%             \includegraphics[width=0.8\textwidth]{figures/part2/autorater_prompt.PNG}
%         \end{figure}
%     }



% \end{minipage}

% % \vspace{2em}

% \begin{center}
%     \only<1>{
%         \includegraphics[width=0.7\textwidth, page=1]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<2>{
%         \includegraphics[width=0.7\textwidth, page=2]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<3>{
%         \includegraphics[height=0.7\textheight]{figures/part2/npov_diagram.pdf}
%     }
%     \only<4>{
%         \includegraphics[width=0.7\textwidth, page=3]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<5>{
%         \includegraphics[width=0.7\textwidth, page=4]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<6>{
%         \includegraphics[width=0.7\textwidth, page=5]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<7>{
%         \includegraphics[width=0.7\textwidth, page=6]{figures/part2/alignment_diagram.pdf}
%     }
% \end{center}
% \end{frame}

%%%%%%%%%%%%%%%%%%% COMECO %%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}{Background on Language Models}
% \only<1-2,4-7>{
% \begin{minipage}[t][9.5em][t]{\textwidth}

%     \only<1>{
%         % \addtocounter{framenumber}{1}
%         \vspace{1em}
%         \textit{Pre-training}: given a dataset 
%         \(\mathcal{D}_{\textup{pre}}\), find \(\theta\) minimizing
%         \begin{equation*}
%             \ell(\theta;\mathcal{D}_{\textup{pre}})
%             = - \sum_{x \in \mathcal{D}_{\textup{pre}}}
%               \sum_{i=1}^{\lvert x \rvert}
%               \log \pi_\theta(x_{i+1} \mid x_{\le i})
%         \end{equation*}
%     }

%     \only<2>{
%         \addtocounter{framenumber}{1}
%         \vspace{1em}
%         \textit{SFT}: given a dataset \(\mathcal{D}_{\textup{SFT}}\), find \(\theta\) minimizing
%         \begin{equation*}
%             \ell(\theta;\mathcal{D}_{\textup{SFT}})
%             = - \sum_{x \in \mathcal{D}_{\textup{SFT}}}
%               \sum_{i=1}^{\lvert x \rvert}
%               \log \pi_\theta(x_{i+1} \mid x_{\le i})
%         \end{equation*}
%     }

%     \only<4-5>{
%         \addtocounter{framenumber}{1}
%         \textcolor{myorange}{\textit{Alignment}} to human preferences via Reinforcement Learning:~\footnotemark[7]\\[-0.25em]
%         \begin{enumerate}
%             \item<4-5> Train a \textit{reward} model {\color{myorange}\(R\)} on \(\mathcal{D}_{\textup{RM}}\)
%             \item<5> Update the \textit{writer} model \(\pi_{\textup{SFT}}\)
%         \end{enumerate}

%         \only<5>{
%         \begin{equation*}
%             \pi_{{\color{lightblue}\beta}}
%             \in \arg\max_{\pi}\,
%             \mathbb{E}_{\substack{x \sim \mathcal{D}_{\textup{RL}} \\ y \sim \pi (y\mid x)}}\!\left[{\color{myorange}R(x, y)}\right]
%             - {\color{lightblue}\beta}\,\mathrm{KL}\!\left(\pi \,\Vert\, \pi_{\textup{SFT}}\right)
%         \end{equation*}
%         }
%     }

%     \only<6>{
%         \addtocounter{framenumber}{1}
%         \textit{Parameter-efficient RL} \(\Rightarrow\) Low-Rank Adaptation (LoRA):~\footnotemark[8]
%         \begin{equation*}
%             \theta = \theta_{\textup{SFT}} + \underbrace{A B}_{\text{low rank}}
%         \end{equation*}
%     }

%     \only<7>{
%     \addtocounter{framenumber}{1}
%     \vspace{1em}
%     Evaluation via \textit{autorater}:\\[0.75em]
%     \begin{center}
%         \includegraphics[width=0.8\textwidth]{figures/part2/autorater_prompt.PNG}
%     \end{center}
% }

% \end{minipage}
% }

% \only<3>{
%     \addtocounter{framenumber}{1}
%     \frametitle{Neutral Point-of-View (NPOV) Task~\textsuperscript{6}}

%     \begin{columns}
%         \begin{column}{0.4\linewidth}
%            \begin{itemize}
%             \item Retrieve data to answer question\\\(\Rightarrow\) \textit{Retrieval Augmented Generation} (RAG)
%             \item RAG allows us to define and measure a hallucinations
%             \item Hallucination (in RAG): content not supported by the retrieved information
%            \end{itemize} 
%         \end{column}
%         \begin{column}{0.6\linewidth}
%             \includegraphics[height=0.85\textheight]{figures/part2/npov_diagram.pdf}
%         \end{column}
%     \end{columns}
%     \grayfootnotetext[6]{\citet{chang2024detectinghallucinationcoverageerrors}}
% }

% \only<1-2,4-7>{
% \begin{center}
%     \only<1>{
%         \includegraphics[width=0.7\textwidth,page=1]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<2>{
%         \includegraphics[width=0.7\textwidth,page=2]{figures/part2/alignment_diagram.pdf}
%     }
%     \only<4>{
%         \includegraphics[width=0.7\textwidth,page=3]{figures/part2/alignment_diagram.pdf}
%         \grayfootnotetext[7]{\citet{christiano2023deepreinforcementlearninghuman}}
%     }
%     \only<5>{
%         \includegraphics[width=0.7\textwidth,page=4]{figures/part2/alignment_diagram.pdf}
%         \grayfootnotetext[7]{\citet{christiano2023deepreinforcementlearninghuman}}
%     }
%     \only<6>{
%         \includegraphics[width=0.7\textwidth,page=5]{figures/part2/alignment_diagram.pdf}
%         \grayfootnotetext[8]{\citet{hu2021loralowrankadaptationlarge}}
%     }
%     \only<7>{
%         \includegraphics[width=0.7\textwidth,page=6]{figures/part2/alignment_diagram.pdf}
%     }
% \end{center}
% }

% \end{frame}
%%%%%%%%%%%%%%%%%%% FIM %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% -------------------------------------------------------
% Frame 1 (old overlay 1)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \vspace{1em}
    \textit{Pre-training}: given a dataset 
    \(\mathcal{D}_{\textup{pre}}\), find \(\theta\) minimizing
    \begin{equation*}
        \ell(\theta;\mathcal{D}_{\textup{pre}})
        = - \sum_{x \in \mathcal{D}_{\textup{pre}}}
          \sum_{i=1}^{|x|}
          \log \pi_\theta(x_{i+1} \mid x_{\le i})
    \end{equation*}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=1]{figures/part2/alignment_diagram.pdf}
\end{center}
\end{frame}

% -------------------------------------------------------
% Frame 2 (old overlay 2)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \vspace{1em}
    \textit{SFT}: given a dataset \(\mathcal{D}_{\textup{SFT}}\), find \(\theta\) minimizing
    \begin{equation*}
        \ell(\theta;\mathcal{D}_{\textup{SFT}})
        = - \sum_{x \in \mathcal{D}_{\textup{SFT}}}
          \sum_{i=1}^{|x|}
          \log \pi_\theta(x_{i+1} \mid x_{\le i})
    \end{equation*}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=2]{figures/part2/alignment_diagram.pdf}
\end{center}
\end{frame}

% -------------------------------------------------------
% Frame 3 â€” NPOV slide (old overlay 3)
% -------------------------------------------------------
\begin{frame}{Neutral Point-of-View (NPOV) Task~\textsuperscript{6}}
\begin{columns}
    \begin{column}{0.4\linewidth}
        \begin{itemize}
            \item<1-> NPOV: equal number of pro / con arguments
            \item<2-> \textit{Retrieval Augmented Generation} (RAG): get more data to answer
            \item<3-> Hallucinations in RAG: content not supported by the retrieved information
        \end{itemize}
    \end{column}
    \begin{column}{0.6\linewidth}
        \includegraphics[height=0.85\textheight]{figures/part2/npov_diagram.pdf}
    \end{column}
\end{columns}

\grayfootnotetext[6]{\citet{chang2024detectinghallucinationcoverageerrors}}
\end{frame}

% -------------------------------------------------------
% Frame 4 (old overlay 4)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \textcolor{myorange}{\textit{Alignment}} to human preferences via Reinforcement Learning:~\footnotemark[7]
    \begin{enumerate}
        \item Train a \textit{reward} model {\color{myorange}R} on \(\mathcal{D}_{\textup{RM}}\)
    \end{enumerate}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=3]{figures/part2/alignment_diagram.pdf}
    \grayfootnotetext[7]{\citet{christiano2023deepreinforcementlearninghuman}}
\end{center}
\end{frame}

% -------------------------------------------------------
% Frame 5 (old overlay 5)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \textcolor{myorange}{\textit{Alignment}} to human preferences via Reinforcement Learning:~\footnotemark[7]
    \begin{enumerate}
        \item Train a \textit{reward} model {\color{myorange}R}
        \item Update the \textit{writer} model \(\pi_{\textup{SFT}}\)
    \end{enumerate}

    \begin{equation*}
        \pi_{{\color{lightblue}\beta}}
        \in \arg\max_{\pi}\,
        \mathbb{E}_{x \sim \mathcal{D}_{\textup{RL}}, y \sim \pi(\cdot\mid x)}
        [{\color{myorange}R(x,y)}]
        - {\color{lightblue}\beta}\,\mathrm{KL}(\pi \,\|\, \pi_{\textup{SFT}})
    \end{equation*}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=4]{figures/part2/alignment_diagram.pdf}
    \grayfootnotetext[7]{\citet{christiano2023deepreinforcementlearninghuman}}
\end{center}
\end{frame}

% -------------------------------------------------------
% Frame 6 (old overlay 6)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \textit{Parameter-efficient RL} \(\Rightarrow\) Low-Rank Adaptation (LoRA):~\footnotemark[8]
    \begin{equation*}
        \theta = \theta_{\textup{SFT}} + \underbrace{AB}_{\text{low rank}}
    \end{equation*}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=5]{figures/part2/alignment_diagram.pdf}
    \grayfootnotetext[8]{\citet{hu2021loralowrankadaptationlarge}}
\end{center}
\end{frame}

% -------------------------------------------------------
% Frame 7 (old overlay 7)
% -------------------------------------------------------
\begin{frame}{Background on Language Models}
\begin{minipage}[t][9.5em][t]{\textwidth}
    \vspace{1em}
    Evaluation via \textit{autorater}:\\[0.75em]
    \begin{center}
        \includegraphics[width=0.8\textwidth]{figures/part2/autorater_prompt.PNG}
    \end{center}
\end{minipage}

\begin{center}
    \includegraphics[width=0.7\textwidth,page=6]{figures/part2/alignment_diagram.pdf}
\end{center}
\end{frame}



\subsection{Reducing Hallucinations with Synthetic Hallucinations}

\begin{frame}{Research question \#1}
\begin{minipage}[t][10em][t]{\textwidth}
    \textbf{Problem}: \(\mathcal{D}_{\textup{RM}}\) is costly, time-consuming, and error-prone to get
    \\[1em]
    Idea: synthetic hallucinations are cheap, fast, error-free
    \begin{tcolorbox}[colback=orange!60!white,
                    colframe=orange!60!white]
        \textbf{Research question \#1:} \\[0.5em]
        Can synthetic hallucinations be used instead?
    \end{tcolorbox}
\end{minipage}
\begin{center}
        \includegraphics[width=0.7\textwidth,page=3]{figures/part2/alignment_diagram.pdf}
\end{center}
\end{frame}

\begin{frame}{Creating Synthetic Hallucinations~\textsuperscript{9}}
\textcolor{mygreen}{Pros:}
\begin{enumerate}
    \item[{\color{mygreen}1.}] \textcolor{mygreen}{Studies show marijuana is a safe drug}
    \item[{\color{mygreen}2.}] \textcolor{mygreen}{Legalization boosts the economy}
\end{enumerate}
{\color{lightblue}
Cons:}
\begin{enumerate}
    \item[{\color{lightblue}1.}] \textcolor{lightblue}{Marijuana is a gateway drug}
    \item[{\color{lightblue}2.}] \textcolor{lightblue}{Legalization brings costs}
\end{enumerate}
\vspace{0.75em}
Neutral answer:\\[0.75em]   
``Some people support marijuana legalization because {\color{mygreen}it would boost the economy} and {\color{mygreen}most studies demonstrate it is a safe drug}. Others oppose it because they see {\color{lightblue}marijuana as a gateway drug}, and its {\color{lightblue}legalization would bring many costs}.''
\grayfootnotetext[9]{\citet{chang2024detectinghallucinationcoverageerrors}}
\end{frame}

\begin{frame}{Creating Synthetic Hallucinations~\textsuperscript{9}}
\textcolor{mygreen}{Pros:}
\begin{enumerate}
    \item[{\color{mygreen}1.}] \textcolor{mygreen}{Studies show marijuana is a safe drug}
    \item[{\color{mygreen}2.}] \textcolor{mygreen}{Legalization boosts the economy}
\end{enumerate}
{\color{lightblue}
Cons:}
\begin{enumerate}
    \item[{\color{lightblue}1.}] \textcolor{lightblue}{\st{Marijuana is a gateway drug}}
    \item[{\color{lightblue}2.}] \textcolor{lightblue}{Legalization brings costs}
\end{enumerate}
\vspace{0.75em}
Neutral answer:\\[0.75em]   
``Some people support marijuana legalization because {\color{mygreen}it would boost the economy} and {\color{mygreen}most studies demonstrate it is a safe drug}. Others oppose it because they see \mycolorbox{red!70!white}{marijuana as a} \mycolorbox{red!70!white}{gateway drug}, and its {\color{lightblue}legalization would bring many costs}.''
\grayfootnotetext[9]{\citet{chang2024detectinghallucinationcoverageerrors}}
\end{frame}

\begin{frame}{Creating Synthetic Hallucinations~\textsuperscript{9}}
    NPOV dataset:
\begin{table}[h]
    \centering
    \begin{tabular}{lcccc}
        \hline
                                 & \textit{Train} & \textit{Validation} & \textit{Test} & \textit{Total}  \\ \hline
        Non-hallucinated         & 335   & 117  & 126  & 578  \\
        Organic hallucinations   & 85    & 30   & 46   & 161  \\
        Synthetic hallucinations & 303   & 98   & 67   & 468  \\ \hdashline[.7pt/1pt]
        Samples                  & 723   & 245  & 239  & 1207 \\ 
        Topics                   & 30    & 14   & 28   & 72   \\ \hline
    \end{tabular}
    % \caption{Description of NPOV dataset. Summary rows (Topics and Samples) are separated by a dashed line.}
    % \label{tab:npov_data}
\end{table}    
\grayfootnotetext[9]{\citet{chang2024detectinghallucinationcoverageerrors}}
\end{frame}

% \begin{frame}{Results}
%     \begin{figure}[h]
%     \centering
%     % Define 3 columns:
%     % 1st column: for the Row Labels (e.g., 2.5cm wide, centered)
%     % 2nd and 3rd columns: for the Images (p-type for alignment)
%     \begin{tabular}{c p{0.48\textwidth} p{0.48\textwidth}} 
    
%         % --- Row 1: Column Labels ---
%         % The first cell is empty, the next two are the column titles
%         & \multicolumn{1}{c}{\textbf{Condition A}} & \multicolumn{1}{c}{\textbf{Condition B}} \\
        
%         % --- Row 2: Row Label + Images ---
%         \multicolumn{1}{c}{\textbf{\rotatebox{90}{Experiment 1}}} & 
%         \includegraphics[width=\textwidth]{figures/part2/npov_rm_organic.png} &
%         \includegraphics[width=\textwidth]{figures/part2/npov_rm_struct.png} \\
        
%         % --- Row 3: Row Label + Images ---
%         \multicolumn{1}{c}{\textbf{\rotatebox{90}{Experiment 2}}} & 
%         \includegraphics[width=\textwidth]{figures/part2/npov_perl_organic_reward.png} &
%         \includegraphics[width=\textwidth]{figures/part2/npov_perl_struct_reward.png} \\
        
%     \end{tabular}
%     \caption{A $2 \times 2$ image grid showing results under different conditions.}
%     \label{fig:2x2_labeled_grid}
% \end{figure}
% \end{frame}

\begin{frame}{Results}
\centering

\begin{table}[h]
    \footnotesize
    \centering
    \begin{tabular}{ccc}
    \toprule
    \textit{SFT baseline} (\%) & \textit{Organic hallucinations} (\%) & \textit{Synthetic hallucinations} (\%) \\
    \midrule
    10.2 & 3.0 & 0.74 \\
    \bottomrule
    \end{tabular}
    \label{tab:npov_results}
\end{table}

% Adjust total width to something safely below slide width
\newlength{\imgw}
\setlength{\imgw}{0.28\textwidth} % tweak if needed

\begin{tabular}{c c c}
    % Column titles
    & \textbf{Organic} & \textbf{Synthetic} \\

    % Row 1
    \rotatebox{90}{\hspace{0.2cm}\textbf{RM ROC-AUC}} &
    \includegraphics[width=\imgw]{figures/part2/npov_rm_organic.png} &
    \includegraphics[width=\imgw]{figures/part2/npov_rm_struct.png} \\

    % Row 2
    \rotatebox{90}{\hspace{0.5cm}\textbf{RL scores}} &
    \includegraphics[width=\imgw]{figures/part2/npov_perl_organic_reward.png} &
    \includegraphics[width=\imgw]{figures/part2/npov_perl_struct_reward.png} \\
\end{tabular}
\end{frame}

\begin{frame}{Example of Hallucination Removed}
    \setlength{\columnsep}{1.5em} 
    \scriptsize

\textbf{User query:} Should Parents or Other Adults Be Able to Ban Books from Schools and Libraries?

\vspace{0.5em}

\begin{columns}[T, totalwidth=\textwidth]
% ------------------- LEFT COLUMN -------------------
\begin{column}{0.48\textwidth}
{\color{mygreen}\textbf{Pros}}
\begin{itemize}
    \item[{\color{mygreen}\ding{118}}] \justifying{{\color{mygreen}Keeping books with inappropriate content out of libraries protects kids but doesn't stop people from reading those books or prevent authors from writing them.}}
    \item[{\color{mygreen}\ding{118}}] \justifying{{\color{mygreen}Parents have the right to decide what material their children are exposed to and when.}}
\end{itemize}

\vspace{0.5em}
{\color{myblue}\textbf{Cons}}
\begin{itemize}
    \item[\textcolor{myblue}{\ding{118}}] \justifying{{\color{myblue}People can better understand the world and their position in it by reading works that are regularly criticized.}}
    \item[\textcolor{myblue}{\ding{118}}] \justifying{{\color{myblue}Books are a portal to different life experiences and reading encourages empathy and social-emotional development.}}
\end{itemize}
\end{column}

% ------------------- RIGHT COLUMN -------------------
\begin{column}{0.48\textwidth}
\textbf{Neutral point-of-view answer (SFT):}

{\scriptsize
\justifying{
This is a very controversial topic. Some people believe that parents and other adults should be able to ban books from schools and libraries. They say that {\color{mygreen}this would protect children from inappropriate content.} However, they also say that {\color{mygreen}this would not stop people from reading those books or prevent authors from writing them.} On the other hand, \mycolorbox{red!70!white}{others say that banning books is} \mycolorbox{red!70!white}{a way to protect children from the world} and that {\color{myblue}it is a way to encourage empathy and social-emotional development.} They also say that {\color{myblue}people can better understand the world and their position in it by reading a number of works that are regularly criticized.}}
}

\end{column}

\end{columns}

\end{frame}


\begin{frame}{Example of Hallucination Removed}
    \setlength{\columnsep}{1.5em} 
    \scriptsize

\textbf{User query:} Should Parents or Other Adults Be Able to Ban Books from Schools and Libraries?

\vspace{0.5em}

\begin{columns}[T, totalwidth=\textwidth]
% ------------------- LEFT COLUMN -------------------
% \begin{column}{0.48\textwidth}
% \begin{minipage}[c][\textheight]{\linewidth}
% \begin{itemize}
%     \item All arguments appear
%     \item Hallucination removed
%     \item Quality of natural language kept
% \end{itemize}
% \end{minipage}
% \end{column}
% \begin{column}{0.48\textwidth}
%     \vspace*{\fill}
%     \begin{itemize}
%         \item All arguments appear
%         \item Hallucination removed
%         \item Quality of natural language kept
%     \end{itemize}
%     \vspace*{\fill}
% \end{column}
\begin{column}{0.48\textwidth}
{\color{mygreen}\textbf{Pros}}
\begin{itemize}
    \item[{\color{mygreen}\ding{118}}] \justifying{{\color{mygreen}Keeping books with inappropriate content out of libraries protects kids but doesn't stop people from reading those books or prevent authors from writing them.}}
    \item[{\color{mygreen}\ding{118}}] \justifying{{\color{mygreen}Parents have the right to decide what material their children are exposed to and when.}}
\end{itemize}

\vspace{0.5em}
{\color{myblue}\textbf{Cons}}
\begin{itemize}
    \item[\textcolor{myblue}{\ding{118}}] \justifying{{\color{myblue}People can better understand the world and their position in it by reading works that are regularly criticized.}}
    \item[\textcolor{myblue}{\ding{118}}] \justifying{{\color{myblue}Books are a portal to different life experiences and reading encourages empathy and social-emotional development.}}
\end{itemize}
\end{column}

% ------------------- RIGHT COLUMN -------------------
\begin{column}{0.48\textwidth}
\textbf{Neutral point-of-view answer (PE-RL):}

{\scriptsize
\justifying{
I don't know what to make of this. Some people say that {\color{mygreen}keeping books with inappropriate content out of libraries protects kids but doesn't stop people from reading those books or prevent authors from writing them.} They say that {\color{mygreen}parents have the right to decide what material their children are exposed to and when}. Others say that {\color{myblue}people can better understand the world and their position in it by reading a number of works that are regularly criticized.} They also say that {\color{myblue}books are a portal to different life experiences and reading encourages empathy and social-emotional development.}}
}

\end{column}

\end{columns}

\end{frame}

\subsection{Decoding-time Realignment of Language Models}

\begin{frame}{Research question \#2}
    \begin{minipage}[t][7em][t]{\textwidth}
    \textbf{Problem}: coefficient \(\textcolor{lightblue}{\beta}\) is expensive to tune via grid-search
    % \\[1em]
    \begin{tcolorbox}[colback=orange!60!white,
                    colframe=orange!60!white]
        \textbf{Research question \#2:} \\[0.5em]
        Can we adjust regularization strength without retraining?
    \end{tcolorbox}
    \end{minipage}
    \begin{center}
        \begin{equation*}
            \pi_{{\color{lightblue}\beta}}
            \in \arg\max_{\pi}\,
            \mathbb{E}_{x \sim \mathcal{D}_{\textup{RL}}, y \sim \pi (y\mid x)}\!\left[{\color{myorange}R(x, y)}\right]
            - {\color{lightblue}\beta}\,\mathrm{KL}\!\left(\pi \,\Vert\, \pi_{\textup{SFT}}\right)
        \end{equation*}\\[0.5em]
            \includegraphics[width=0.7\textwidth,page=5]{figures/part2/alignment_diagram.pdf}
    \end{center}
\end{frame}

\begin{frame}{Closed-form solution}
    \begin{itemize}
        \item Closed-form solution to alignment objective:%~\footnotemark[10]
        \begin{equation*}
            \pi_\beta (y \vert x) = \frac{\pi_{\textup{SFT}}(y \vert x) \, \exp \left(\frac{1}{\beta} R(x, y) \right)}{\sum_{y^\prime} \pi_{\textup{SFT}}(y^\prime \vert x) \, \exp \left(\frac{1}{\beta} R(x, y^\prime) \right)}
        \end{equation*}
        \pause
        \item For \(\beta^\prime = \beta / \lambda\), after some algebra:
        \begin{equation*}
            \pi_{\beta / \lambda} (y \vert x) = \frac{\pi_{\textup{SFT}} (y \vert x) \left( \frac{\pi_\beta (y \vert x)}{\pi_{\textup{SFT}}(y \vert x)} \right)^\lambda}{\sum_{y^\prime} \pi_{\textup{SFT}} (y^\prime \vert x) \left( \frac{\pi_\beta (y^\prime \vert x)}{\pi_{\textup{SFT}}(y \vert x)} \right)^\lambda}
        \end{equation*}
        \pause
        \item Sum over \(y^\prime\), and \(\pi_\beta\) on functional space \(\rightarrow\) intractable
    \end{itemize}
% \grayfootnotetext[10]{\citet{ziegler2020finetuninglanguagemodelshuman}}
\end{frame}

\begin{frame}{Results}
    \addtocounter{framenumber}{-1}
    \begin{itemize}
        \item Idea: change \(y, y^\prime \to\) current trajectory \(\{y_i\}_{i=1, \dotsc, t}\), fit \(\pi_\beta\)
        \item Approximate realigned model at \(\beta / \lambda\):~\footnotemark[11]
    \end{itemize}
        \vspace{0.75em}
        \begin{align*}
            \hat{\pi}_{\beta/\lambda} (y_t \vert x, y_{<t}) &\coloneqq 
            \frac{\pi_{\textup{SFT}} (y_t \vert x, y_{<t}) \left( \frac{\pi_\beta (y_t \vert x, y_{<t})}{\pi_{\textup{SFT}}(y_t \vert x, y_{<t})} \right)^\lambda}{\sum_{y_t} \pi_{\textup{SFT}} (y_t \vert x, y_{<t}) \left( \frac{\pi_\beta (y_t \vert x, y_{<t})}{\pi_{\textup{SFT}}(y_t \vert x, y_{<t})} \right)^\lambda} \\[0.75em] 
            &\hphantom{=}{\color{white} \textup{softmax} \left[ \lambda h_\beta^{(t)} + (1 - \lambda) h_{\textup{SFT}}^{(t)} \right]}
        \end{align*}
    \begin{itemize}
        \item[] {\color{white}where \(h^{(t)}_{\textup{SFT}}\) and \(h^{(t)}_{\beta}\) are the logits }
        \begin{align*}
            {\color{white}
            \begin{cases}
                \pi_{\textup{SFT}} (\, \cdot \, \vert x, y_{< t}) &= \textup{softmax} (h^{(t)}_{\textup{SFT}}) \\[0.75em]
                \pi_{\beta} (\, \cdot \, \vert x, y_{< t}) &= \textup{softmax} (h^{(t)}_{\beta})
            \end{cases}
            }
        \end{align*}
    \end{itemize}
\grayfootnotetext[11]{Liu, \textbf{Bianco} et al. (2024)}
\end{frame}

\begin{frame}{Results}
    \begin{itemize}
        \item Idea: change \(y, y^\prime \to\) current trajectory \(\{y_i\}_{i=1, \dotsc, t}\), fit \(\pi_\beta\)
        \item Approximate realigned model at \(\beta / \lambda\):~\footnotemark[11]
    \end{itemize}
        \vspace{0.75em}
        \begin{align*}
            \hat{\pi}_{\beta/\lambda} (y_t \vert x, y_{<t}) &\coloneqq 
            \frac{\pi_{\textup{SFT}} (y_t \vert x, y_{<t}) \left( \frac{\pi_\beta (y_t \vert x, y_{<t})}{\pi_{\textup{SFT}}(y_t \vert x, y_{<t})} \right)^\lambda}{\sum_{y_t} \pi_{\textup{SFT}} (y_t \vert x, y_{<t}) \left( \frac{\pi_\beta (y_t \vert x, y_{<t})}{\pi_{\textup{SFT}}(y_t \vert x, y_{<t})} \right)^\lambda} \\[0.75em] 
            &= \textup{softmax} \left[ \lambda h_\beta^{(t)} + (1 - \lambda) h_{\textup{SFT}}^{(t)} \right]
        \end{align*}
    \begin{itemize}
        \item[] where \(h^{(t)}_{\textup{SFT}}\) and \(h^{(t)}_{\beta}\) are the logits 
        \begin{align*}
            \begin{cases}
                \pi_{\textup{SFT}} (\, \cdot \, \vert x, y_{< t}) &= \textup{softmax} (h^{(t)}_{\textup{SFT}}) \\[0.75em]
                \pi_{\beta} (\, \cdot \, \vert x, y_{< t}) &= \textup{softmax} (h^{(t)}_{\beta})
            \end{cases}
        \end{align*}
    \end{itemize}
\grayfootnotetext[11]{Liu, \textbf{Bianco} et al. (2024)}
\end{frame}

\begin{frame}{Results for the NPOV task}
    \begin{columns}
        \begin{column}{0.4\linewidth}
            \begin{itemize}
                \item When \(\lambda \ll 1\)\\\(\Rightarrow\) too close to \(\pi_{\textup{SFT}}\)
                {\uncover<2->{\item When \(\lambda \gg 1\)\\\(\Rightarrow\) ``reward hacking''}}
                {\uncover<3->{\item Sweet spot: \(\lambda \approx 2\)\\\(\Rightarrow\) retrain for \(\beta/2\)}}
            \end{itemize}
        \end{column}
        \begin{column}{0.6\linewidth}
            \begin{figure}
                \centering
                \includegraphics[scale=0.55]{figures/part2/dera-hallucination-single-col.pdf}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Results for a summarization task}
    \begin{figure}
        \centering
        \includegraphics[scale=0.5]{figures/part2/length_reward_result_no_sax.pdf}
    \end{figure}
\end{frame}

\begin{frame}{Discussion for Language Model Alignment}
    \begin{itemize}
        \item \textbf{Main takeaway}: efficient hallucination reduction using PE-RL with synthetic data and DeRA hyperparameter optimization.
        \item \textbf{Code}: {\color{lightblue}\url{github.com/leobianco/perl_hallucination}}\\[0.75em]
        \begin{itemize}
            \item[{\color{lightblue}\ding{81}}] Open-source implementation
            \item[{\color{lightblue}\ding{81}}] Entire pipeline: creating synthetic hallucinations, parameter-efficient SFT, RM, and RL loop, calibration of autorater and evaluation of hallucination rate
            \item[{\color{lightblue}\ding{81}}] Open-weights models: Gemma, Mistral, Qwen...
        \end{itemize}
        \item Perspectives: other tasks (summarization), models (Mistral, Qwen), synthetic hallucinations schemes (LLMs)
    \end{itemize}
\end{frame}

% \begin{frame}{Results}
%     \begin{figure}
%         \centering
%         \includegraphics[scale=0.5]{figures/part2/length_reward_result_no_sax.pdf}
%     \end{figure}
% \end{frame}

% \begin{frame}{Discussion}
%     \begin{itemize}
%         \item ?
%     \end{itemize}
% \end{frame}
